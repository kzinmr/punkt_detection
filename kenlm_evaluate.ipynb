{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kneser-Ney smoothingによるn-gram言語モデルを使った句点挿入(評価)\n",
    "\n",
    "## [KenLM](https://github.com/kpu/kenlm) で学習済みのモデル(*.klm)を用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "LM = 'data/3gram.100K.klm'\n",
    "model = kenlm.Model(LM)\n",
    "print('{0}-gram model'.format(model.order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KenLM API デモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '今日 も いい 天気 です 。 明日 の 天気 も 晴れ らしい 。'\n",
    "print(model.score(sentence))\n",
    "def score(s):\n",
    "    return sum(prob for prob, _, _ in model.full_scores(s))\n",
    "# Check that total full score = direct score\n",
    "assert (abs(score(sentence) - model.score(sentence)) < 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_scores(sentence):\n",
    "    # Show scores and n-gram matches\n",
    "    words = ['<s>'] + sentence.split() + ['</s>']\n",
    "    full_score = 0.\n",
    "    for i, (prob, length, oov) in enumerate(model.full_scores(sentence)):\n",
    "        ngram = words[i+2-length:i+2]\n",
    "        words_s = ' '.join(ngram)\n",
    "        print('{0} {1}: {2}'.format(prob, length, words_s))\n",
    "        if oov:\n",
    "            print('\\t\"{0}\" is an OOV'.format(words[i+1]))\n",
    "        full_score+=prob\n",
    "    print(full_score)\n",
    "full_scores(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 句読点挿入モデル\n",
    "## 各位置で句点を挿入する/しないで文全体の尤度比較し、尤度が上がれば句点挿入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punkt_insert(sentence, punkt='。', window=3, debug=False):\n",
    "    words = sentence.split()\n",
    "    pnkt_pos = []\n",
    "    for i in range(len(words)-window+1):\n",
    "        prob = model.score(' '.join(words))\n",
    "        prob_p = model.score(' '.join(words[:i+window] + [punkt] + words[i+window:]))\n",
    "        if prob_p > prob:\n",
    "            if debug:\n",
    "                print(prob_p, prob, words[i:i+window])\n",
    "            pnkt_pos.append(i+window)\n",
    "    return pnkt_pos\n",
    "\n",
    "def punkt_decode(sentence, punkt_pos, punkt='。'):\n",
    "    words = sentence.split()\n",
    "    pnkt_sent = []\n",
    "    for i in range(len(words)):\n",
    "        pnkt_sent.append(words[i])\n",
    "        if i+1 in punkt_pos:\n",
    "            pnkt_sent.append(punkt)\n",
    "    return ' '.join(pnkt_sent)\n",
    "\n",
    "def test_decode(sentence, punkt='。'):\n",
    "    ins = punkt_decode(sentence, punkt_insert(sentence, punkt=punkt, debug=True), punkt=punkt)\n",
    "    print(ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 句点挿入による尤度変化の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_raw = '競馬 の 業務 ・ 運営 を 行う 目的 と 関係 者 や 観客 が 観戦 を する 目的 を 兼ね備え た 施設 スタンド 内 に は 観客 が 立ち入る こと が できる スペース 馬主 など の 関係 者 が 立ち入る こと が 出来る スペース 運営 スタッフ のみ が 立ち入る こと が 出来る スペース が 明確 に 区切ら れ て いる それぞれ 自分 に 関係 し ない スペース へ の 立ち入り は 堅く 禁じ られ て いる 日本 で は 走路 の 決勝 線 の ある 側 の 外周 に 作ら れる こと が 多い 以下 で は スタンド 内 に 併設 さ れ て いる 設備 や 装置 を 説明 する 決勝 線 の 延長線 上 に 設け られ て おり 写真 判定 に 用いる 写真 を ゴール 板 を 利用 し て 撮影 する 中 は レース が 始まる と 真っ暗 闇 に なり 決勝 写真 を 撮り 終え たら すぐさま 手探り で フィルム を 現像 し 下 の 階 の 審判 室 に エレベーター で 送ら れる 勝馬 投票 券 （ 馬券 ） の 販売 ならびに 払い戻し を 行う 設備 かつて は 有人 の 発券 ・ 払い戻し 窓口 が ずらりと 並ん で い た が 現在 は 人件 費 削減 ・ 省力 化 の ため に 機械 化 さ れ て いる 窓口 が 多い なお 一部 は 払い戻し も 兼ね た 兼用 機 に なっ て いる 場合 も ある 対面 式 の 有人 窓口 も ある が これ について も マークシート 使用 による 窓口 と なっ て いる 場合 が 多い 口頭 による 窓口 販売 は ごく 一部 の 窓口 に 限ら れ て いる 一部 に マークカード 対応 窓口 しか ない 競馬 場 も ある が この 場合 でも バリアフリー の 観点 など から マークカード を 扱え ない 障害 者 や 高齢 者 の 馬券 購入 希望 が ある 場合 これ に 応じ て 特定 の 有人 窓口 の 端末 を 手動 操作 する こと など で 発券 対応 し て いる'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decode(sentence_raw, '。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_true = '競馬 の 業務 ・ 運営 を 行う 目的 と 関係 者 や 観客 が 観戦 を する 目的 を 兼ね備え た 施設 。 スタンド 内 に は 観客 が 立ち入る こと が できる スペース 、 馬主 など の 関係 者 が 立ち入る こと が 出来る スペース 、 運営 スタッフ のみ が 立ち入る こと が 出来る スペース が 明確 に 区切ら れ て いる 。 それぞれ 自分 に 関係 し ない スペース へ の 立ち入り は 堅く 禁じ られ て いる 。 日本 で は 走路 の 決勝 線 の ある 側 の 外周 に 作ら れる こと が 多い 。 以下 で は スタンド 内 に 併設 さ れ て いる 設備 や 装置 を 説明 する 。 決勝 線 の 延長線 上 に 設け られ て おり 、 写真 判定 に 用いる 写真 を ゴール 板 を 利用 し て 撮影 する 。 中 は レース が 始まる と 真っ暗 闇 に なり 決勝 写真 を 撮り 終え たら すぐさま 手探り で フィルム を 現像 し 、 下 の 階 の 審判 室 に エレベーター で 送ら れる 。 勝馬 投票 券 （ 馬券 ） の 販売 ならびに 払い戻し を 行う 設備 。 かつて は 有人 の 発券 ・ 払い戻し 窓口 が ずらりと 並ん で い た が 、 現在 は 人件 費 削減 ・ 省力 化 の ため に 機械 化 さ れ て いる 窓口 が 多い 。 なお 、 一部 は 払い戻し も 兼ね た 兼用 機 に なっ て いる 場合 も ある 。 対面 式 の 有人 窓口 も ある が これ について も マークシート 使用 による 窓口 と なっ て いる 場合 が 多い 。 口頭 による 窓口 販売 は ごく 一部 の 窓口 に 限ら れ て いる 。 一部 に マークカード 対応 窓口 しか ない 競馬 場 も ある が 、 この 場合 でも バリアフリー の 観点 など から マークカード を 扱え ない 障害 者 や 高齢 者 の 馬券 購入 希望 が ある 場合 、 これ に 応じ て 特定 の 有人 窓口 の 端末 を 手動 操作 する こと など で 発券 対応 し て いる 。'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価\n",
    "## 句読点付き文に対して、句点抜き文への句点挿入の精度と再現率を評価\n",
    "### 現状、句点か読点かいずれか一方(punkt)の挿入のみ実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句読点付き文から句点挿入位置を抽出\n",
    "def extract_positions(sentence, punkt='。'):\n",
    "    PUNKTS = ['、', '。']\n",
    "    true_positions = []\n",
    "    c_pos = 0\n",
    "    for w in sentence.split(' '):\n",
    "        if w in PUNKTS:\n",
    "            if w == punkt:\n",
    "                true_positions.append(c_pos)\n",
    "        else:\n",
    "            c_pos += 1\n",
    "    return true_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句読点無し文に対する句点挿入位置の予測結果から精度と再現率を計算\n",
    "def prf(punkt_pred, punkt_true):\n",
    "    tp = set.intersection(punkt_pred, punkt_true)      \n",
    "    precision = len(tp) / len(punkt_true) if len(punkt_true) > 0 else 0\n",
    "    recall = len(tp) / len(punkt_pred) if len(punkt_pred) > 0 else 0\n",
    "    fval = 2 / (1/precision + 1/recall) if precision and recall else 0.\n",
    "    return precision, recall, fval\n",
    "\n",
    "# 句点未挿入の文に対して精度・再現率を計算\n",
    "def evaluate(sentence_raw, sentence_true, punkt='。'):\n",
    "    punkt_pred = set(punkt_insert(sentence_raw, punkt))\n",
    "    punkt_true = set(extract_positions(sentence_true, punkt))\n",
    "    return prf(punkt_pred, punkt_true)\n",
    "\n",
    "# 句点挿入済み結果の文に対して精度・再現率を計算\n",
    "def evaluate_sym(sentence_pred, sentence_true, punkt='。'):\n",
    "    punkt_pred = set(extract_positions(sentence_pred, punkt))\n",
    "    punkt_true = set(extract_positions(sentence_true, punkt))\n",
    "    return prf(punkt_pred, punkt_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上の文について計算\n",
    "evaluate(sentence_raw, sentence_true, punkt='。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価単体テスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 低Recallの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_raw = 'この 場合 でも バリアフリー の 観点 など から マークカード を 扱え ない 障害 者 や 高齢 者 の 馬券 購入 希望 が ある 場合 これ に 応じ て 特定 の 有人 窓口 の 端末 を 手動 操作 する こと など で 発券 対応 し て いる'\n",
    "sentence_true = 'この 場合 でも バリアフリー の 観点 など から マークカード を 扱え ない 障害 者 や 高齢 者 の 馬券 購入 希望 が ある 場合 、 これ に 応じ て 特定 の 有人 窓口 の 端末 を 手動 操作 する こと など で 発券 対応 し て いる 。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挿入位置\n",
    "punkt_insert(sentence_raw, punkt='。', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解位置\n",
    "extract_positions(sentence_true, punkt='。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P/R/F計算\n",
    "evaluate(sentence_raw, sentence_true, punkt='。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 低Precisionの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_raw = '今日 も いい 天気 明日 の 天気 も 晴れ らしい'\n",
    "sentence_true = '今日 も 、 いい 天気 。 明日 の 天気 も 晴れ らしい 。' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挿入位置\n",
    "punkt_insert(sentence_raw, punkt='。', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解位置\n",
    "extract_positions(sentence_true, punkt='。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P/R/F計算\n",
    "evaluate(sentence_raw, sentence_true, punkt='。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータによる評価\n",
    "## 未知語置換済み / 適当にカット済みデータに対して評価\n",
    "### 比較的まともに終了するサイズとして、約10文ごとの文ブロックを1万ブロック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# 頻度上位100,000以下は未知語記号<UNK>で置換\n",
    "vocab_path = 'data/train.txt.100K' # 学習に使ったデータセット\n",
    "target_path = 'data/target_test.txt'\n",
    "source_path = 'data/source_test.txt'\n",
    "\n",
    "with open(vocab_path) as fp:\n",
    "    vocab = set(chain.from_iterable([l.split(' ') for l in fp.read().splitlines()]))\n",
    "\n",
    "with open(target_path) as tfp, open(source_path) as sfp, \\\n",
    "     open(target_path+'.100K', 'w') as tofp, \\\n",
    "     open(source_path+'.100K', 'w') as sofp:\n",
    "    for tl, sl in zip(tfp,sfp):\n",
    "        words_to_write = []\n",
    "        for w in tl.strip().split(' '):\n",
    "            if w in vocab:\n",
    "                words_to_write.append(w)\n",
    "            elif '、' in w:\n",
    "                words_to_write.append('、')\n",
    "            elif '。' in w:\n",
    "                words_to_write.append('。')\n",
    "            else:\n",
    "                words_to_write.append('<UNK>')\n",
    "        tofp.write(' '.join(words_to_write)+'\\n')\n",
    "        words_to_write = []\n",
    "        for w in sl.strip().split(' '):\n",
    "            if w in vocab:\n",
    "                words_to_write.append(w)\n",
    "            else:\n",
    "                words_to_write.append('<UNK>')\n",
    "        sofp.write(' '.join(words_to_write)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUND = 10000\n",
    "with open('data/source_test.txt.100K') as fp:\n",
    "    source_test = fp.read().splitlines()[:BOUND]\n",
    "with open('data/target_test.txt.100K') as fp:\n",
    "    target_test = fp.read().splitlines()[:BOUND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micros = []\n",
    "with open('data/prf.100K.{}'.format(BOUND), 'w') as ofp:\n",
    "    for sent_raw, sent_true in zip(source_test, target_test):\n",
    "        if len(extract_positions(sent_true)) > 0:\n",
    "            p, r, f = evaluate(sent_raw, sent_true)\n",
    "            ofp.write('{0:5g} {1:5g} {2:5g}\\n'.format(p,r,f))\n",
    "            micros.append((p,r,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "micros = np.array(micros)\n",
    "print(micros.mean(axis=0), len(micros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上までで十分だが、エラー分析のため一旦句点挿入したのちPRF値評価もする場合も評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/source_test.txt.100K') as fp, open('data/decoded.100K.{}'.format(BOUND), 'w') as ofp:\n",
    "    for sent_raw in fp.read().splitlines()[:BOUND]:\n",
    "        ofp.write(punkt_decode(sent_raw, punkt_insert(sent_raw.strip()))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/decoded.100K.{}'.format(BOUND)) as fp:\n",
    "    decoded = fp.read().splitlines()\n",
    "with open('data/target_test.txt.100K') as fp:\n",
    "    target_test = fp.read().splitlines()[:BOUND]\n",
    "print('\\n'.join(decoded[:3]))\n",
    "print('\\n'.join(target_test[:3]))\n",
    "for sent_raw, sent_true in zip(decoded[:5], target_test[:5]):\n",
    "    print(evaluate_sym(sent_raw, sent_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/decoded.100K.{}'.format(BOUND)) as fp:\n",
    "    decoded = fp.read().splitlines()\n",
    "with open('data/target_test.txt.100K') as fp:\n",
    "    target_test = fp.read().splitlines()[:BOUND]\n",
    "micros = []\n",
    "with open('data/prf.100K.{}.d'.format(BOUND), 'w') as ofp:\n",
    "    for sent_raw, sent_true in zip(decoded, target_test):\n",
    "        p, r, f = evaluate_sym(sent_raw, sent_true)\n",
    "        ofp.write('{0:5g} {1:5g} {2:5g}\\n'.format(p,r,f))\n",
    "        micros.append((p,r,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "micros = np.array(micros)\n",
    "print(micros.mean(axis=0), micros.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
